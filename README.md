# Tarea 1 â€“ Reconocimiento de DÃ­gitos con MLP

Repositorio para la Tarea 1 de **EL7060-1 Deep Learning para Procesamiento de SeÃ±ales**, Universidad de Chile.  
El objetivo es implementar un **reconocedor de dÃ­gitos aislados en inglÃ©s** usando un **Multilayer Perceptron (MLP)** en PyTorch.

---

## ğŸ“‚ Estructura del repositorio

Tarea1-DeepLearning/
â”‚â”€â”€ data/ # scripts o instrucciones para descargar TiDigits
â”‚â”€â”€ src/
â”‚ â”‚â”€â”€ preprocessing.py # extracciÃ³n de caracterÃ­sticas (Mel Filter Bank)
â”‚ â”‚â”€â”€ model.py # definiciÃ³n del MLP
â”‚ â”‚â”€â”€ train.py # entrenamiento + validaciÃ³n
â”‚ â”‚â”€â”€ evaluate.py # evaluaciÃ³n (accuracy + matriz de confusiÃ³n)
â”‚â”€â”€ notebooks/ # experimentos en Jupyter/Colab
â”‚â”€â”€ results/ # mÃ©tricas, grÃ¡ficos y matriz de confusiÃ³n
â”‚â”€â”€ report/ # informe (mÃ¡x. 6 pÃ¡ginas)
â”‚â”€â”€ slides/ # presentaciones avance/final
â”‚â”€â”€ README.md # este archivo
â”‚â”€â”€ requirements.txt # dependencias

yaml
Copy code

---

## ğŸš€ InstalaciÃ³n

1. Clonar el repositorio:
   ```bash
   git clone https://github.com/usuario/Tarea1-DeepLearning.git
   cd Tarea1-DeepLearning
Crear un entorno virtual (opcional, recomendado):

bash
Copy code
python3 -m venv venv
source venv/bin/activate  # en Linux/Mac
venv\Scripts\activate     # en Windows
Instalar dependencias:

bash
Copy code
pip install -r requirements.txt
ğŸ“Š Dataset
Se utiliza la base de datos TiDigits (descargable desde el link entregado en el enunciado).

Guardar los audios en data/.

Las particiones ya estÃ¡n dadas en train, valid y test.

ğŸ› ï¸ Uso
Preprocesamiento (ejemplo con Mel Filter Bank):

bash
Copy code
python src/preprocessing.py
Entrenamiento:

bash
Copy code
python src/train.py --epochs 50 --batch_size 32 --lr 0.001
EvaluaciÃ³n:

bash
Copy code
python src/evaluate.py
Los resultados (accuracy, matriz de confusiÃ³n) se guardarÃ¡n en la carpeta results/.

ğŸ“ˆ Resultados esperados
Accuracy en test set

Matriz de confusiÃ³n entre las 11 clases (0â€“9 + dÃ­gito "oh").

ğŸ“‘ Entregables
CÃ³digo funcionando (este repo).

Informe (mÃ¡x. 6 pÃ¡ginas).

Presentaciones (avance y final).

ğŸ“Œ Consideraciones
Justificar hiperparÃ¡metros: tasa de aprendizaje, dropout, batch size, early stopping, etc.

Comparar resultados para distintos valores.

Discutir ventajas y limitaciones del MLP en esta tarea.

Analizar efecto de usar features dinÃ¡micos.

ğŸ‘¥ Autores

Alejandro
Marcelo